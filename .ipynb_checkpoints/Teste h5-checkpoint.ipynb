{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_model('layer10_epoc100_kernel5p5_dropout0p3.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2b31f504ba8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Convolution2D, MaxPool2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['Image'] = training['Image'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape((96,96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([training['Image']], dtype=np.uint8).reshape(training.shape[0],96,96,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training.drop(['Image'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ndarray = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_ndarray, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.871717492367991\n",
      "Test accuracy: 1.4890272617340088\n"
     ]
    }
   ],
   "source": [
    "score = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.871717492367991, 1.4890272617340088, 0.7788162231445312]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\alexandre\\miniconda3\\envs\\tensorflow\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\alexandre\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from h5py) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\alexandre\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from h5py) (1.17.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List \n",
      "  ['model_weights', 'optimizer_weights']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('layer10_epoc100_kernel7p7_drop0p1.hdf5', 'r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    print('List \\n ', ls)\n",
    "    model_weights = hdf.get('model_weights')\n",
    "    model_weights = np.array(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_normalization_3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['batch_normalization_1', 'batch_normalization_10',\n",
       "       'batch_normalization_2', 'batch_normalization_3',\n",
       "       'batch_normalization_4', 'batch_normalization_5',\n",
       "       'batch_normalization_6', 'batch_normalization_7',\n",
       "       'batch_normalization_8', 'batch_normalization_9', 'conv2d_1',\n",
       "       'conv2d_10', 'conv2d_2', 'conv2d_3', 'conv2d_4', 'conv2d_5',\n",
       "       'conv2d_6', 'conv2d_7', 'conv2d_8', 'conv2d_9', 'dense_1',\n",
       "       'dense_2', 'dropout_1', 'flatten_1', 'leaky_re_lu_1',\n",
       "       'leaky_re_lu_10', 'leaky_re_lu_2', 'leaky_re_lu_3',\n",
       "       'leaky_re_lu_4', 'leaky_re_lu_5', 'leaky_re_lu_6', 'leaky_re_lu_7',\n",
       "       'leaky_re_lu_8', 'leaky_re_lu_9', 'max_pooling2d_1',\n",
       "       'max_pooling2d_2', 'max_pooling2d_3', 'max_pooling2d_4',\n",
       "       'max_pooling2d_5'], dtype='<U22')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
